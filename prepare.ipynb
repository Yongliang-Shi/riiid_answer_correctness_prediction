{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: to prepare the data for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Monitor memory use and time\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  42.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((411517, 18), (50842, 18), (52868, 18))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data from local files\n",
    "df_train = pd.read_csv('data_2000users/train.csv')\n",
    "df_validate = pd.read_csv('data_2000users/validate.csv')\n",
    "df_test = pd.read_csv('data_2000users/test.csv')\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "df_train.shape, df_validate.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  42.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13523, 6), (418, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data from local files\n",
    "df_ques = pd.read_csv('questions_with_tag_counts.csv', index_col=0)\n",
    "df_lects = pd.read_csv('lectures_with_part_name.csv', index_col=0)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "df_ques.shape, df_lects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns from Kaggle questions.csv and lectures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  42.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((411517, 9), (50842, 9), (52868, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns merged from questions.csv and lectures.csv\n",
    "cols = ['lecture_id', 'tag', 'lecture_part', 'type_of', 'question_id',\n",
    "        'bundle_id', 'correct_answer', 'question_part', 'tags']\n",
    "\n",
    "df_train = df_train.drop(columns = cols)\n",
    "df_validate = df_validate.drop(columns = cols)\n",
    "df_test = df_test.drop(columns = cols)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "df_train.shape, df_validate.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features:\n",
    "- user_acc_mean\n",
    "- user_lectures_running_total\n",
    "- avg_user_q_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  62.3\n",
      "CPU times: user 2.18 s, sys: 181 ms, total: 2.36 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((411517, 13), (50842, 12), (52868, 12))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = prepare.sam_train_features(df_train)\n",
    "validate = prepare.sam_valtest_features(train, df_validate)\n",
    "test = prepare.sam_valtest_features(train, df_test)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0  1864702        5720                0                  0   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            1                   1                          NaN   \n",
       "\n",
       "  prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                            NaN       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  \n",
       "0  45951.0       11917302.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop user ids to save memory\n",
    "\n",
    "# train.drop(columns='user_id', inplace=True)\n",
    "# validate.drop(columns='user_id', inplace=True)\n",
    "# test.drop(columns='user_id', inplace=True)\n",
    "\n",
    "# train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle nulls and the np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45951</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>28391.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0  1864702        5720                0                  0   \n",
       "1      45951  1864702        5204                0                  1   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            1                   1                          NaN   \n",
       "1            1                   0                          inf   \n",
       "\n",
       "  prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                            NaN       0.630049                            0   \n",
       "1                          False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  \n",
       "0  45951.0       11917302.0  \n",
       "1  28391.0       11917302.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45951</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>28391.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0  1864702        5720                0                  0   \n",
       "1      45951  1864702        5204                0                  1   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            1                   1                          0.0   \n",
       "1            1                   0                          0.0   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "1                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  \n",
       "0  45951.0       11917302.0  \n",
       "1  28391.0       11917302.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle nulls\n",
    "train = prepare.handle_null(train)\n",
    "validate = prepare.handle_null(validate)\n",
    "test = prepare.handle_null(test)\n",
    "    \n",
    "# Handle the inf values\n",
    "train = prepare.handle_inf(train)\n",
    "validate = prepare.handle_inf(validate)\n",
    "test = prepare.handle_inf(test)\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate lecture rows and question rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to separate the lecture rows and question rows\n",
    "\n",
    "def seperate_rows(df):\n",
    "    '''\n",
    "    separate the lecture rows and question rows\n",
    "    '''\n",
    "    mask_question = (df['answered_correctly'] != -1)\n",
    "    mask_lecture = (df['answered_correctly'] == -1)\n",
    "    df_question = df[mask_question]\n",
    "    df_lecture = df[mask_lecture]\n",
    "    return df_question, df_lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((403377, 13), (8140, 13))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function on train, validate, and test\n",
    "\n",
    "train, train_lects = seperate_rows(train)\n",
    "validate, validate_lects = seperate_rows(validate)\n",
    "test, test_lects = seperate_rows(test)\n",
    "\n",
    "train.shape, train_lects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge: \n",
    "- train, validate and test with df_ques\n",
    "- train_lects with df_lects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45951</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>28391.0</td>\n",
       "      <td>11917302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0  1864702        5720                0                  0   \n",
       "1      45951  1864702        5204                0                  1   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            1                   1                          0.0   \n",
       "1            1                   0                          0.0   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "1                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  \n",
       "0  45951.0       11917302.0  \n",
       "1  28391.0       11917302.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  62.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((403377, 19), (49945, 18), (51971, 18))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge train/validate/test with df_ques\n",
    "\n",
    "train = train.merge(df_ques, how='left', left_on='content_id', right_on='question_id')\n",
    "validate = validate.merge(df_ques, how='left', left_on='content_id', right_on='question_id')\n",
    "test = test.merge(df_ques, how='left', left_on='content_id', right_on='question_id')\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>5720</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0  1864702        5720                0                  0   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            1                   1                          0.0   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  question_id  bundle_id  correct_answer  part  \\\n",
       "0  45951.0       11917302.0         5720       5720               1     5   \n",
       "\n",
       "  tags  tag_count  \n",
       "0  115          1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns to drop**\n",
    "- timestamp: used to compute avg time each user to answer 1 question\n",
    "- content_id (question_id): after drop the lecture rows, used to compute average question mean\n",
    "- content_type_id: **drop**\n",
    "- task_container_id: used to compute avereage task mean\n",
    "- user_answer: **drop**\n",
    "- answered_correctly: target varibale\n",
    "- prior_question_elapsed_time: **drop**\n",
    "- prior_question_had_explanation: used for question_had_explanation\n",
    "- correct_answer: **drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  63.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((403377, 15), (49945, 14), (51971, 14))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the redundant column to save memory\n",
    "\n",
    "train.drop(columns=['content_type_id', 'user_answer', \n",
    "                    'prior_question_elapsed_time', 'correct_answer'], inplace=True)\n",
    "validate.drop(columns=['content_type_id', 'user_answer', \n",
    "                       'prior_question_elapsed_time', 'correct_answer'], inplace=True)\n",
    "test.drop(columns=['content_type_id', 'user_answer', \n",
    "                   'prior_question_elapsed_time', 'correct_answer'], inplace=True)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>5720</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0  1864702        5720                  0                   1   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  question_id  bundle_id  part tags  tag_count  \n",
       "0  45951.0       11917302.0         5720       5720     5  115          1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train dataset\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features:\n",
    "- part accuracy\n",
    "- bundle accuray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_bundle_features(train, validate, test):\n",
    "    \n",
    "    # Calculate the average accuracy for each unique bundle id\n",
    "    bundle_accuracy = train.groupby(['bundle_id'])['answered_correctly'].mean().round(2).to_frame().reset_index()\n",
    "    bundle_accuracy.columns = ['bundle_id', 'mean_bundle_accuracy']\n",
    "    \n",
    "    # Add bundle mean accuracy as a feature to train, validate, and test\n",
    "    merged_train = train.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    merged_validate = validate.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    merged_test = test.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    \n",
    "    # Calculate the average part accuracy\n",
    "    tag_accuracy = train.groupby(['part'])['answered_correctly'].agg(['mean']).round(2).reset_index()\n",
    "    tag_accuracy.columns = ['part', 'mean_part_accuracy']\n",
    "    \n",
    "    # Add average part accuracy\n",
    "    train_df = merged_train.merge(tag_accuracy, left_on='part', right_on='part')\n",
    "    validate_df = merged_validate.merge(tag_accuracy, left_on='part', right_on='part')\n",
    "    test_df = merged_test.merge(tag_accuracy, left_on='part', right_on='part')\n",
    "    \n",
    "    # Calculate the mean container accuracy for each part\n",
    "    tag_bundles = train.groupby(['question_id', 'task_container_id', 'part'])['answered_correctly'].mean().round(2).reset_index()\n",
    "    tag_bundles.rename(columns={'answered_correctly': 'mean_container_part_accuracy'}, inplace=True)\n",
    "    tag_bundles.drop(columns='question_id', inplace=True)\n",
    "    \n",
    "#     # Add mean container part accuracy\n",
    "#     train_set = train_df.merge(tag_bundles, how='left', \n",
    "#                                left_on=['task_container_id', 'part'], \n",
    "#                                right_on=['task_container_id', 'part'])\n",
    "    \n",
    "#     validate_set = validate_df.merge(tag_bundles, how='left', \n",
    "#                                      left_on=['task_container_id', 'part'], \n",
    "#                                      right_on=['task_container_id', 'part'])\n",
    "    \n",
    "#     test_set = test_df.merge(tag_bundles, how='left', \n",
    "#                              left_on=['task_container_id', 'part'], \n",
    "#                              right_on=['task_container_id', 'part'])\n",
    "\n",
    "    \n",
    "    return train_df, validate_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  64.5\n",
      "CPU times: user 338 ms, sys: 93.4 ms, total: 431 ms\n",
      "Wall time: 431 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((403377, 17), (49945, 16), (51971, 16))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train, validate, test = part_bundle_features(train, validate, test)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>5720</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0  1864702        5720                  0                   1   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  question_id  bundle_id  part tags  tag_count  \\\n",
       "0  45951.0       11917302.0         5720       5720     5  115          1   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  \n",
       "0                  0.82                0.61  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features\n",
    "- content accuracy\n",
    "- task accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momoery usage:  64.6\n",
      "CPU times: user 7.07 s, sys: 180 ms, total: 7.25 s\n",
      "Wall time: 7.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((403377, 19), (49945, 18), (51971, 18))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = prepare.merge_with_stats_train(train)\n",
    "validate = prepare.merge_with_stats_valortest(train, validate)\n",
    "test = prepare.merge_with_stats_valortest(train, test)\n",
    "\n",
    "print(\"Momoery usage: \", psutil.virtual_memory().percent)\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "      <th>mean_content_accuracy</th>\n",
       "      <th>mean_task_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>5720</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.682248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0  1864702        5720                  0                   1   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  question_id  bundle_id  part tags  tag_count  \\\n",
       "0  45951.0       11917302.0         5720       5720     5  115          1   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  mean_content_accuracy  \\\n",
       "0                  0.82                0.61               0.818182   \n",
       "\n",
       "   mean_task_accuracy  \n",
       "0            0.682248  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features:\n",
    "- mean tagcount accuracy\n",
    "- mean tags accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_count\n",
       "1    0.62\n",
       "2    0.68\n",
       "3    0.67\n",
       "4    0.69\n",
       "5    0.71\n",
       "6    0.76\n",
       "Name: mean_tagcount_accuracy, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy on eveary part\n",
    "\n",
    "mean_tagcount_accuracy = train.groupby('tag_count').answered_correctly.mean().round(2).rename('mean_tagcount_accuracy')\n",
    "mean_tagcount_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tags\n",
       "1                0.60\n",
       "1 162            0.62\n",
       "10 111 92        0.70\n",
       "10 164 102       0.79\n",
       "10 164 162 29    0.94\n",
       "Name: mean_tags_accuracy, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy on eveary part\n",
    "\n",
    "mean_tags_accuracy = train.groupby('tags').answered_correctly.mean().round(2).rename('mean_tags_accuracy')\n",
    "mean_tags_accuracy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on train\n",
    "\n",
    "train = train.merge(mean_tagcount_accuracy, how='left', on='tag_count')\n",
    "train = train.merge(mean_tags_accuracy, how='left', on='tags')\n",
    "\n",
    "validate = validate.merge(mean_tagcount_accuracy, how='left', on='tag_count')\n",
    "validate = validate.merge(mean_tags_accuracy, how='left', on='tags')\n",
    "\n",
    "test = test.merge(mean_tagcount_accuracy, how='left', on='tag_count')\n",
    "test = test.merge(mean_tags_accuracy, how='left', on='tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>...</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "      <th>mean_content_accuracy</th>\n",
       "      <th>mean_task_accuracy</th>\n",
       "      <th>mean_tagcount_accuracy</th>\n",
       "      <th>mean_tags_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>45951.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5720</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.682248</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45951</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>28391.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5204</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.534988</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74342</td>\n",
       "      <td>1864702</td>\n",
       "      <td>4094</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>22436.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4094</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96778</td>\n",
       "      <td>1864702</td>\n",
       "      <td>9699</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>36191.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9699</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.544008</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132969</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5889</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>24322.0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5889</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.485282</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0  1864702        5720                  0                   1   \n",
       "1      45951  1864702        5204                  1                   0   \n",
       "2      74342  1864702        4094                  2                   1   \n",
       "3      96778  1864702        9699                  3                   1   \n",
       "4     132969  1864702        5889                  4                   0   \n",
       "\n",
       "   prior_question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                           False       0.630049                            0   \n",
       "1                           False       0.630049                            0   \n",
       "2                           False       0.630049                            0   \n",
       "3                           False       0.630049                            0   \n",
       "4                           False       0.630049                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  ...  bundle_id  part  tags tag_count  \\\n",
       "0  45951.0       11917302.0  ...       5720     5   115         1   \n",
       "1  28391.0       11917302.0  ...       5204     5   173         1   \n",
       "2  22436.0       11917302.0  ...       4094     5     1         1   \n",
       "3  36191.0       11917302.0  ...       9699     5    55         1   \n",
       "4  24322.0       11917302.0  ...       5889     5    89         1   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  mean_content_accuracy  \\\n",
       "0                  0.82                0.61               0.818182   \n",
       "1                  0.55                0.61               0.550000   \n",
       "2                  0.44                0.61               0.444444   \n",
       "3                  0.41                0.61               0.406250   \n",
       "4                  0.69                0.61               0.687500   \n",
       "\n",
       "   mean_task_accuracy  mean_tagcount_accuracy  mean_tags_accuracy  \n",
       "0            0.682248                    0.62                0.79  \n",
       "1            0.534988                    0.62                0.65  \n",
       "2            0.445216                    0.62                0.60  \n",
       "3            0.544008                    0.62                0.62  \n",
       "4            0.485282                    0.62                0.62  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                         0\n",
       "user_id                           0\n",
       "content_id                        0\n",
       "task_container_id                 0\n",
       "answered_correctly                0\n",
       "prior_question_had_explanation    0\n",
       "user_acc_mean                     0\n",
       "user_lectures_running_total       0\n",
       "avg_user_q_time                   0\n",
       "question_id                       0\n",
       "bundle_id                         0\n",
       "part                              0\n",
       "tags                              0\n",
       "tag_count                         0\n",
       "mean_bundle_accuracy              0\n",
       "mean_part_accuracy                0\n",
       "mean_content_accuracy             0\n",
       "mean_task_accuracy                0\n",
       "mean_tagcount_accuracy            0\n",
       "mean_tags_accuracy                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.fillna(0.5, inplace=True)\n",
    "test.fillna(0.5, inplace=True)\n",
    "\n",
    "validate.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift prior question had explanation to current question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift prior question had explanation to current question\n",
    "\n",
    "train.prior_question_had_explanation = train.prior_question_had_explanation.shift(-1)\n",
    "validate.prior_question_had_explanation = validate.prior_question_had_explanation.shift(-1)\n",
    "test.prior_question_had_explanation = test.prior_question_had_explanation.shift(-1)\n",
    "\n",
    "train = train.rename(columns={\"prior_question_had_explanation\": \"question_had_explanation\"})\n",
    "validate = validate.rename(columns={\"prior_question_had_explanation\": \"question_had_explanation\"})\n",
    "test = test.rename(columns={\"prior_question_had_explanation\": \"question_had_explanation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_exploration.csv')\n",
    "validate.to_csv('validate_exploration.csv')\n",
    "test.to_csv('test_exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'user_id', 'content_id', 'task_container_id',\n",
       "       'answered_correctly', 'question_had_explanation', 'user_acc_mean',\n",
       "       'user_lectures_running_total', 'q_time', 'avg_user_q_time',\n",
       "       'question_id', 'bundle_id', 'part', 'tags', 'tag_count',\n",
       "       'mean_bundle_accuracy', 'mean_part_accuracy', 'mean_content_accuracy',\n",
       "       'mean_task_accuracy', 'mean_tagcount_accuracy', 'mean_tags_accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the q_time in the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "      <th>mean_content_accuracy</th>\n",
       "      <th>mean_task_accuracy</th>\n",
       "      <th>mean_tagcount_accuracy</th>\n",
       "      <th>mean_tags_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1864702</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0</td>\n",
       "      <td>11917302.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>5720</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.682248</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0  1864702        5720                  0                   1   \n",
       "\n",
       "  question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                    False       0.630049                            0   \n",
       "\n",
       "   avg_user_q_time  question_id  bundle_id  part tags  tag_count  \\\n",
       "0       11917302.0         5720       5720     5  115          1   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  mean_content_accuracy  \\\n",
       "0                  0.82                0.61               0.818182   \n",
       "\n",
       "   mean_task_accuracy  mean_tagcount_accuracy  mean_tags_accuracy  \n",
       "0            0.682248                    0.62                0.79  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s = train.drop(columns='q_time')\n",
    "train_s.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns not needed for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp', 'user_id', 'content_id', 'task_container_id',\n",
    "        'question_id', 'bundle_id', 'part', 'tags', 'tag_count']\n",
    "\n",
    "train_s = train_s.drop(columns=cols)\n",
    "validate_s = train.drop(columns=cols)\n",
    "test_s = train.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert boolean to num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_to_num(df):\n",
    "    \"\"\"\n",
    "    Accepts df. Converts True and False values into 1's and 0's resepectively, within the \n",
    "    question_had_explanation column.\n",
    "    \"\"\"\n",
    "    df = df.fillna(False)\n",
    "    m = df.question_had_explanation.apply(lambda i: 1 if i == True else 0)\n",
    "    df.question_had_explanation = m\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = boolean_to_num(train_s)\n",
    "validate_s = boolean_to_num(validate_s)\n",
    "test_s = boolean_to_num(test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answered_correctly                    0\n",
       "question_had_explanation              0\n",
       "user_acc_mean                         0\n",
       "q_time                                0\n",
       "mean_bundle_accuracy                  0\n",
       "mean_part_accuracy                    0\n",
       "mean_content_accuracy                 0\n",
       "mean_task_accuracy                    0\n",
       "mean_tagcount_accuracy                0\n",
       "mean_tags_accuracy                    0\n",
       "user_lectures_running_total_scaled    0\n",
       "avg_user_q_time_scaled                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(train, validate, test, columns_to_scale):\n",
    "    '''\n",
    "    Accepts train, validate, test and list of columns to scale. Scales listed columns.\n",
    "    '''\n",
    "    new_column_names = [c + '_scaled' for c in columns_to_scale]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(train[columns_to_scale])\n",
    "\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        pd.DataFrame(scaler.transform(train[columns_to_scale]), columns=new_column_names, index=train.index),\n",
    "    ], axis=1)\n",
    "\n",
    "    validate = pd.concat([\n",
    "        validate,\n",
    "        pd.DataFrame(scaler.transform(validate[columns_to_scale]), columns=new_column_names, index=validate.index),\n",
    "    ], axis=1)\n",
    "\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        pd.DataFrame(scaler.transform(test[columns_to_scale]), columns=new_column_names, index=test.index),\n",
    "    ], axis=1)\n",
    "    \n",
    "    train.drop(columns=columns_to_scale, inplace=True)\n",
    "    validate.drop(columns=columns_to_scale, inplace=True)\n",
    "    test.drop(columns=columns_to_scale, inplace=True)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_scale = ['user_lectures_running_total', 'avg_user_q_time']\n",
    "\n",
    "train_s, validate_s, test_s = scale(train_s, validate_s, test_s, columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "      <th>mean_content_accuracy</th>\n",
       "      <th>mean_task_accuracy</th>\n",
       "      <th>mean_tagcount_accuracy</th>\n",
       "      <th>mean_tags_accuracy</th>\n",
       "      <th>user_lectures_running_total_scaled</th>\n",
       "      <th>avg_user_q_time_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.682248</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answered_correctly question_had_explanation  user_acc_mean  \\\n",
       "0                   1                    False       0.630049   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  mean_content_accuracy  \\\n",
       "0                  0.82                0.61               0.818182   \n",
       "\n",
       "   mean_task_accuracy  mean_tagcount_accuracy  mean_tags_accuracy  \\\n",
       "0            0.682248                    0.62                0.79   \n",
       "\n",
       "   user_lectures_running_total_scaled  avg_user_q_time_scaled  \n",
       "0                                 0.0                0.001202  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train_s\n",
    "train_s.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train, validate, test DFs that only include non-target variables\n",
    "X_train = train_s.drop(columns='answered_correctly')\n",
    "y_train = train_s['answered_correctly']\n",
    "\n",
    "X_validate = validate_s.drop(columns='answered_correctly')\n",
    "y_validate = validate_s['answered_correctly']\n",
    "\n",
    "X_test = test_s.drop(columns='answered_correctly')\n",
    "y_test = test_s['answered_correctly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_had_explanation              0\n",
       "user_acc_mean                         0\n",
       "mean_bundle_accuracy                  0\n",
       "mean_part_accuracy                    0\n",
       "mean_content_accuracy                 0\n",
       "mean_task_accuracy                    0\n",
       "mean_tagcount_accuracy                0\n",
       "mean_tags_accuracy                    0\n",
       "user_lectures_running_total_scaled    0\n",
       "avg_user_q_time_scaled                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBest_ranker(X, y, n):\n",
    "    '''\n",
    "    Returns the top n selected features with their scores based on the SelectKBest calss\n",
    "    Parameters: scaled predictors(X) in df, target(y) in df, the number of features to select(n)\n",
    "    '''\n",
    "\n",
    "    # parameters: f_regression stats test, give me 5 features\n",
    "    f_selector = SelectKBest(f_classif, k=n)\n",
    "\n",
    "    # Fit on X and y\n",
    "    f_selector.fit(X, y)\n",
    "\n",
    "    # boolean mask of whether the column was selected or not. \n",
    "    feature_score = f_selector.scores_.round(2)\n",
    "\n",
    "    # Put the features in a dataframe\n",
    "    df_features = pd.DataFrame({'features': X.columns, \n",
    "                                'score': feature_score})\n",
    "\n",
    "    # Sort the features based on their score\n",
    "    df_features.sort_values(by=\"score\", ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "    # Compute how many features in X\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Add a rank column\n",
    "    df_features['rank'] = range(1, m+1)\n",
    "    \n",
    "    return df_features[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_content_accuracy</td>\n",
       "      <td>76690.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_bundle_accuracy</td>\n",
       "      <td>55971.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_acc_mean</td>\n",
       "      <td>22419.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_tags_accuracy</td>\n",
       "      <td>21599.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_task_accuracy</td>\n",
       "      <td>15910.84</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>question_had_explanation</td>\n",
       "      <td>3954.75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean_part_accuracy</td>\n",
       "      <td>3397.75</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_tagcount_accuracy</td>\n",
       "      <td>2389.41</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_lectures_running_total_scaled</td>\n",
       "      <td>211.82</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_user_q_time_scaled</td>\n",
       "      <td>116.95</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features     score  rank\n",
       "0               mean_content_accuracy  76690.75     1\n",
       "1                mean_bundle_accuracy  55971.00     2\n",
       "2                       user_acc_mean  22419.10     3\n",
       "3                  mean_tags_accuracy  21599.32     4\n",
       "4                  mean_task_accuracy  15910.84     5\n",
       "5            question_had_explanation   3954.75     6\n",
       "6                  mean_part_accuracy   3397.75     7\n",
       "7              mean_tagcount_accuracy   2389.41     8\n",
       "8  user_lectures_running_total_scaled    211.82     9\n",
       "9              avg_user_q_time_scaled    116.95    10"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "df = KBest_ranker(X_train, y_train, 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
